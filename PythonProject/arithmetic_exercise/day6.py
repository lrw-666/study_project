"""贪心"""
# 由一系列选择组成，考虑当下此刻所能采取的措施，并证明它们可以工作
# 如找零总是从大数值的开始找
# 算法步骤：1.先列出可能的配对方案，并将其合拍度按降序排列
# 2.从该列表中选出第一个没有被使用过的配对方案
# 3.检查该配对方案中的人是否被占用，是就放弃，否就采纳
# 4.检查列表中是否还有更多的配对方案，若是就跳转第二步
# 核心设计思路：确保每一次贪心选择的安全

# 一种配对问题：求婚者与稳定婚姻
# 1.每个未婚男士都必须向他喜欢的单尚未求过婚的女士求婚
# 2.每位女士都会暂时与自己喜欢的追求者订婚，并拒绝其他
# 安全性：不可能喜欢他人胜过自己的配偶

# 背包问题：有一组想要带在身边的物品，每个物品都有各自的质量和价值，但背包有一个最大容量，如何才使所带物品总价值最大
# 分数背包问题：无须将整体对象考虑在内，优先选择最好的，重点是找到权重比
# 如只需将每一克的金沙、威士忌和豆腐各自的价值排个序，然后按概念一个个装包就行

# 整数背包问题：设现在依然要对多个类别的对象就行处理，就要每个类别都增加一个总数值，并且每个类别对象都有一个固定质量及有关特有的价值
# 还可分为无边界和有边界两种重要情况
# 有边界会假设每个类别中的对象数量是固定的，而无边界对象时想要多少有多少，但贪心策略在这两种情况不可行(时间效率不行，动态规划策略设计出伪多项式级时间)

# 哈夫曼算法：典型的贪心算法——如在急救中心担任接听求救电话的工作，要根据一些列yes\no问题来诊断求救者的紧急医疗问题，并采取适当措施
# 还有一份“必须涵盖条件”列表，以及诊断问题、严重程度和发生频率的信息
# 简化相关问题：我们需要一种加权平衡（平衡二叉树结构是在发生概率均匀分布的前提下构建的），尽量减少期望会遇到的问题的数量，就得（剪枝法）尽可能的减少从根节点到叶节点的预期深度
# 相关树结构的目标依然相同，即如何在深度（u）x权值（v)之和最小的情况下，遍历完每个叶节点u
# 例压缩领域的用某种可变长度的编码来表示文本（结构中任意有效代码不可能是其他代码的前缀——前缀码）
# 贪心策略：从出现概率最大的字符开始，一个个添加字符，但问题是添加到哪里
# 另一种方式：先形成分段式解决方案，形成若干个树结构分段，然后将这些分段反复合并起来。每当将两个树合并时，就添加一个新的共享根节点，并赋予它与所有子节点之和相等的加权值
# 哈夫曼算法：维护着一个局部解决方案，形成一个森林结构，其中的每个树结构都是一个多层内嵌列表，
# 只要森林结构中还存在两个以上彼此独立的树结构，就从中选出两个分量最轻的树，合并后再放回原处，并赋予其根节点新的加权值
from heapq import heapify, heappush, heappop
from itertools import count # 用于轻松生成无限递归序列
def huffman(seq, frq):
    num = count()
    trees = list(zip(frq, num, seq))
    heapify(trees) # 创建最小堆(使数组转化为堆),反复选取、合并两个最小无序列表项本是一个平方级操作，现简化为线性对数级操作
    while len(trees) > 1:
        fa, _, a = heappop(trees) # 删除堆顶（即最小值）
        fb, _, b = heappop(trees)
        n = next(num)
        heappush(trees, (fa+fb, n, [a, b]))
    return trees[0][-1]
seq = "abcdefghi"
frq = [4, 5, 6, 9, 11, 12, 15, 16, 20]
print(huffman(seq, frq))
# 在两者之间再增加一个字段，来区别所有对象，这里增加一个计数器(不兼容对象之间的比较操作-列表与字符串)
# 预处理与后期加工：对各字符出现的概率进行计数
# 从哈夫曼树中提取出哈夫曼编码
def codes(tree, prefix=""):
    if len(tree) == 1:
        yield (tree, prefix)
        return
    for bit, child in zip('01', tree): # 左0右1
        for pair in codes(child, prefix + bit):
            yield pair

# 哈夫曼如何用贪心策略(选出两个权值最轻的元素作为树结构最底层中的兄弟节点)将该结构达到任何一个也节点的预期深度实现最小
# 归纳法：证明操作自始至终都是安全的——分为两个部分
# 1.贪心选择性：每次都通过贪心选择得到了一个最优解决方案的一部分   用置换辩论来证明——先假设一种最佳方案，然后看看能否将其逐步演变到我们的解决方案上，并不出现更糟糕的情况
# 2.最优子结构：做出选择后剩下的问题(子问题)和原有问题有着同样的解决方案
# 最优化归并：哈夫曼树可实现节点权重的最小化，哈夫曼树中，最小化权重值就等于其遍历所有叶节点的深度乘以权重值的和
# Python的标准库的压缩处理模块zipfile模块处理的是zip文件，所用的压缩技术就基于哈夫曼编码

"""最小生成树问题"""
# 最小生成树问题：找到用于连接某图中所有节点的、最便宜的方式，并且要假定我们只能基于某个该图的边线子集来完成这项工作
# 假设一棵连通无向图G的生成树T，其节点集与G相同，但边集是后者的子集。若将G与边的某种权重W(e)关联起来，即边e的权重等于w(e)，其生成树的权重w(T)就等于T中每一条边e的权重w(e)之和
# 找出一种权重最小但能覆盖整个G的生成树(可能不止一种)，若G为非连通图，则不存在生成树结构
# 贪心策略：我们可以通过每次增加一条边线的方式来逐步构建该树结构，在每一个步骤中，选择当前构建过程中所能允许加入的、值最低的那条边

# 最短边问题：
# 最小生成树中一定会包含最短边(Kruskal算法，接近原型的贪心算法)
# 用某种方式连通b节点与其他节点，选择短的边(Prim算法，在遍历基础上运用了贪心选择的技术)
# 上两种思想为剪切的特殊情况，一种剪切将图中节点划分为两个集合，关注的是连通两个节点集之间的边
# 剪切关键：我们确信能安全的把跨越该剪切的最短边包括进来
# 理解：在图中选择最短边是安全的，因为该边也必然在该节点与图中其他任意节点之间画出的剪切中是最短边

# Kruskal算法：先对图中的边进行排序(权重)，然后着手进行选取，
# 标记解决方案中的每一个节点来了解他们各自所属的部分(树结构，检查边是否已存在)，可从每个部分的节点中选择一个来充当代表，让该部分的所有节点都指向他
# Kruskal算法实现的朴素版：
def naive_find(C, u):
    while C[u] != u:
        u = C[u]
    return u

def naive_union(C, u, v):
    u = naive_find(C, u)
    v = naive_find(C, v)
    C[u] = v

def naive_kruskal(G):
    E = [(G[u][v], u, v) for u in G for v in G[u]]
    T = set()
    C = {u: u for u in G}
    for _, u, v in sorted(E):
        if naive_find(C, u) != naive_find(C, v):
            T.add((u, v))
            naive_union(C, u, v)
    return T
# Kruskal算法
def find(C, u):
    if C[u] != u:
        C[u] = find(C, C[u])
    return C[u]

def union(C, R, u, v):
    u, v = find(C, u), find(C, v)
    if R[u] > R[v]:
        C[v] = u
    else:
        C[u] = v
    if R[u] == R[v]:
        R[v] += 1

def kruskal(G):
    E = [(G[u][v], u, v) for u in G for v in G[u]]
    T = set()
    C, R = {u: u for u in G}, {u: 0 for u in G}
    for _, u, v in sorted(E):
        if find(C, u) != find(C, v):
            T.add((u, v))
            union((C, R, u, v))
    return T

# Prim算法：从某个起始节点开始对目标图结构进行遍历，并将最短的连接边加入到相对应的树结构中
# 问题：可能发现一条新的边指向的是已被放到队列中的节点，若新边比之前发现的边更短，就得基于新边来调整优先级
# 解决：通过直接多次添加同一节点——每当我们通过一条边找到一个节点时，就直接根据其权值将其添加到相应的堆结构中(若重复，保留权值低的)
# heapq不支持像list.sort（）那样排序用的键值函数，所以在堆结构中采用“权值、节点”对的形式来实现
def prim(G, s):
    P, Q = {}, [(0, None, s)]
    while Q:
        _, p, u = heappop(Q)
        if u in p:
            continue
        P[u] = p
        for v, w in G[u].items():
            heappush(Q, (w, u, v))
        return P

"""何时贪心"""
# 保持领先策略:证明我们在一步一个脚印地构建出属于自己的解决方案时，贪心算法始终会越来越逼近某个假想的最优解决方案
# 例：资源调度问题——把最早完成的区间纳入当前解决方案，排除其他所有与第一步结构重叠的区间，若还有剩余区间，重新执行第一步
# 修改：持续时间与截止期限，对于如何超时的任务，都会给予一次值等于其延迟长度的惩罚，目的就是要最小化这些延迟的最大值
# 解决：始终坚持执行当前最紧迫的任务

# 确保贪心算法正确性从两方面入手：
# 1.证明贪心策略的选择属性，即证明贪心选择的是最优选择
# 2.证明最优化子结构，即证明其剩余子问题是其本身的一个更小实例